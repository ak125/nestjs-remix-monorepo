// app/routes/robots[.]txt.tsx
/**
 * ü§ñ ROBOTS.TXT - Align√© avec structure PHP
 * 
 * R√®gles PHP originales:
 * - Disallow: /_form.get.car.* (formulaires AJAX)
 * - Disallow: /fiche/ (fiches produits - duplicate content)
 * - Disallow: /find/ (recherche g√©n√©rale)
 * - Disallow: /searchmine/ (recherche par type mine)
 * - Disallow: /account/ (espace client priv√©)
 * 
 * Optimisations v2:
 * - Timeout + retry automatique
 * - Cache long (24h browser, 48h CDN)
 * - Fallback complet si backend indisponible
 * 
 * @see backend/src/modules/seo/services/robots-txt.service.ts
 */
import { type LoaderFunctionArgs } from "@remix-run/node";
import {
  SITEMAP_CONFIG,
  fetchWithRetry,
  logSitemapError,
} from "~/lib/sitemap-fetch";

/**
 * G√©n√©rer le robots.txt de fallback
 */
function generateFallbackRobots(): string {
  return `# ===========================================
# ü§ñ ROBOTS.TXT - AutoMecanik.com (Fallback)
# ===========================================

User-agent: *
Allow: /

# ‚ùå Blocages h√©rit√©s du syst√®me PHP
Disallow: /_form.get.car.*
Disallow: /fiche/
Disallow: /find/
Disallow: /searchmine/
Disallow: /account/

# ‚ùå Blocages additionnels
Disallow: /admin/
Disallow: /api/
Disallow: /checkout/
Disallow: /cart/

# ‚è±Ô∏è Crawl-delay
Crawl-delay: 1

# üìç Sitemaps
Sitemap: ${SITEMAP_CONFIG.BASE_URL}/sitemap.xml
Sitemap: ${SITEMAP_CONFIG.BASE_URL}/sitemap-constructeurs.xml
Sitemap: ${SITEMAP_CONFIG.BASE_URL}/sitemap-types.xml
Sitemap: ${SITEMAP_CONFIG.BASE_URL}/sitemap-blog.xml`;
}

export async function loader({ request }: LoaderFunctionArgs) {
  const startTime = Date.now();

  try {
    // ‚úÖ Robots.txt depuis backend via API (√©vite boucle r√©cursive /robots.txt)
    // IMPORTANT: On utilise /api/seo/robots.txt au lieu de /robots.txt
    // car /robots.txt serait intercept√© par Remix lui-m√™me (boucle infinie)
    const response = await fetchWithRetry(
      `${SITEMAP_CONFIG.BACKEND_URL}/api/seo/robots.txt`
    );

    const robotsTxt = await response.text();
    const duration = Date.now() - startTime;

    return new Response(robotsTxt, {
      headers: {
        "Content-Type": "text/plain; charset=utf-8",
        "Cache-Control": "public, max-age=86400, s-maxage=172800, stale-while-revalidate=3600",
        "Vary": "Accept-Encoding",
        "X-Response-Time": `${duration}ms`,
      },
    });
  } catch (error) {
    const duration = Date.now() - startTime;
    logSitemapError('Robots.txt', error, duration);

    return new Response(generateFallbackRobots(), {
      headers: {
        "Content-Type": "text/plain; charset=utf-8",
        "Cache-Control": "public, max-age=3600",
        "X-Error": "Backend unavailable - fallback robots.txt",
        "X-Response-Time": `${duration}ms`,
      },
    });
  }
}
