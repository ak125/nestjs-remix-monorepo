#!/bin/bash

# ==============================================================================
# Script d'analyse du taux de crawl du sitemap
# ==============================================================================
#
# KPI: % d'URLs du sitemap crawl√©es dans les derni√®res 72h
#
# Mesure la r√©activit√© des moteurs de recherche au sitemap
# Objectif: >80% des URLs crawl√©es en <72h apr√®s publication/mise √† jour
#

set -e

LOKI_URL=${LOKI_URL:-http://localhost:3100}
SITEMAP_URL=${SITEMAP_URL:-https://automecanik.fr/sitemap.xml}
TIME_WINDOW=${1:-72h}  # Fen√™tre de temps (72h par d√©faut)

echo "üîç Analyse du taux de crawl du sitemap"
echo "======================================"
echo "Sitemap: $SITEMAP_URL"
echo "Fen√™tre: $TIME_WINDOW"
echo "Loki: $LOKI_URL"
echo ""

# 1. R√©cup√©rer les URLs du sitemap
echo "üìã R√©cup√©ration des URLs du sitemap..."
SITEMAP_URLS=$(curl -s "$SITEMAP_URL" | \
    grep -o '<loc>[^<]*</loc>' | \
    sed 's/<loc>//g;s/<\/loc>//g' | \
    wc -l)

echo "‚úÖ $SITEMAP_URLS URLs trouv√©es dans le sitemap"
echo ""

# 2. Requ√™te Loki pour compter les URLs crawl√©es (bots uniquement)
echo "ü§ñ Analyse des crawls dans les derni√®res $TIME_WINDOW..."

# Query LogQL pour compter les URLs uniques crawl√©es par des bots
LOGQL_QUERY='count(count_over_time({job="caddy-access"} | json | bot != "" | __error__="" ['"$TIME_WINDOW"'])) by (path)'

# Encoder la query pour URL
ENCODED_QUERY=$(echo "$LOGQL_QUERY" | jq -sRr @uri)

# Requ√™te Loki
LOKI_RESPONSE=$(curl -s -G "$LOKI_URL/loki/api/v1/query" \
    --data-urlencode "query=$LOGQL_QUERY" \
    --data-urlencode "time=$(date +%s)")

# Extraire le nombre d'URLs crawl√©es
CRAWLED_URLS=$(echo "$LOKI_RESPONSE" | jq -r '.data.result | length // 0')

echo "‚úÖ $CRAWLED_URLS URLs uniques crawl√©es par des bots"
echo ""

# 3. Calculer le KPI
if [ "$SITEMAP_URLS" -gt 0 ]; then
    CRAWL_RATE=$(awk "BEGIN {printf \"%.2f\", ($CRAWLED_URLS / $SITEMAP_URLS) * 100}")
    
    echo "üìä KPI - Taux de crawl"
    echo "======================"
    echo "URLs dans sitemap: $SITEMAP_URLS"
    echo "URLs crawl√©es ($TIME_WINDOW): $CRAWLED_URLS"
    echo "Taux de crawl: $CRAWL_RATE%"
    echo ""
    
    # √âvaluation du KPI
    THRESHOLD=80
    if (( $(echo "$CRAWL_RATE >= $THRESHOLD" | bc -l) )); then
        echo "‚úÖ EXCELLENT - Taux > ${THRESHOLD}%"
        echo "   Les moteurs de recherche crawlent activement votre site!"
    elif (( $(echo "$CRAWL_RATE >= 50" | bc -l) )); then
        echo "‚ö†Ô∏è  MOYEN - Taux entre 50% et ${THRESHOLD}%"
        echo "   Am√©liorer: fr√©quence mise √† jour sitemap, robots.txt, PageSpeed"
    else
        echo "‚ùå FAIBLE - Taux < 50%"
        echo "   Actions urgentes:"
        echo "   - V√©rifier robots.txt"
        echo "   - Soumettre sitemap √† Google Search Console"
        echo "   - Am√©liorer temps de chargement"
        echo "   - V√©rifier que le sitemap est accessible"
    fi
else
    echo "‚ùå Erreur: Aucune URL trouv√©e dans le sitemap"
    exit 1
fi

echo ""

# 4. Top 10 des bots les plus actifs
echo "ü§ñ Top 10 des bots crawlers"
echo "==========================="

TOP_BOTS_QUERY='{job="caddy-access"} | json | bot != "" | __error__="" ['"$TIME_WINDOW"']'
TOP_BOTS=$(curl -s -G "$LOKI_URL/loki/api/v1/query" \
    --data-urlencode "query=topk(10, sum by (bot) (count_over_time($TOP_BOTS_QUERY)))" \
    --data-urlencode "time=$(date +%s)")

echo "$TOP_BOTS" | jq -r '.data.result[] | "\(.metric.bot): \(.value[1]) hits"' | \
    awk '{printf "  %2d. %s\n", NR, $0}'

echo ""

# 5. URLs les plus crawl√©es
echo "üìÑ Top 10 des URLs les plus crawl√©es"
echo "====================================="

TOP_URLS_QUERY='{job="caddy-access"} | json | bot != "" | __error__="" ['"$TIME_WINDOW"']'
TOP_URLS=$(curl -s -G "$LOKI_URL/loki/api/v1/query" \
    --data-urlencode "query=topk(10, sum by (path) (count_over_time($TOP_URLS_QUERY)))" \
    --data-urlencode "time=$(date +%s)")

echo "$TOP_URLS" | jq -r '.data.result[] | "\(.metric.path): \(.value[1]) crawls"' | \
    awk '{printf "  %2d. %s\n", NR, $0}'

echo ""
echo "üí° Conseils pour am√©liorer le taux de crawl:"
echo "   - Soumettre le sitemap r√©guli√®rement (Google Search Console, Bing Webmaster)"
echo "   - Mettre √† jour <lastmod> dans le sitemap apr√®s chaque modification"
echo "   - Ajouter <changefreq> et <priority> pertinents"
echo "   - Am√©liorer le temps de r√©ponse du serveur (<200ms)"
echo "   - Cr√©er un sitemap index pour sites >50k URLs"
echo "   - Utiliser robots.txt pour guider les crawlers"
