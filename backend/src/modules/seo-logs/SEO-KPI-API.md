# üìä API SEO KPI - Guide d'utilisation

## Vue d'ensemble

L'API SEO KPI expose les m√©triques de crawl analys√©es √† partir des logs Caddy stock√©s dans Loki. Elle permet de monitorer en temps r√©el l'activit√© des moteurs de recherche sur votre site.

**Base URL:** `/seo-logs/kpi`

---

## Endpoints

### 1. ü§ñ Taux de crawl du sitemap

**GET** `/seo-logs/kpi/crawl-rate`

Calcule le pourcentage d'URLs du sitemap crawl√©es par les bots dans une fen√™tre de temps.

#### Param√®tres

| Param | Type | D√©faut | Description |
|-------|------|--------|-------------|
| `timeWindow` | string | `72h` | Fen√™tre de temps (ex: `24h`, `72h`, `7d`, `30d`) |

#### Exemple de requ√™te

```bash
curl http://localhost:3001/seo-logs/kpi/crawl-rate?timeWindow=72h
```

#### Exemple de r√©ponse

```json
{
  "success": true,
  "data": {
    "timeWindow": "72h",
    "sitemap": {
      "url": "https://automecanik.fr/sitemap.xml",
      "totalUrls": 5420
    },
    "crawl": {
      "crawledUrls": 4512,
      "crawlRate": 83.25,
      "status": "excellent",
      "threshold": 80
    },
    "evaluation": {
      "status": "excellent",
      "recommendation": "Excellent taux de crawl! Les moteurs de recherche indexent activement votre site."
    },
    "updatedAt": "2025-10-26T14:23:45.123Z"
  }
}
```

#### Statuts et seuils

| Taux | Statut | Signification |
|------|--------|---------------|
| ‚â• 80% | `excellent` | Crawl tr√®s actif ‚úÖ |
| 60-79% | `good` | Crawl normal üëç |
| 40-59% | `warning` | Crawl insuffisant ‚ö†Ô∏è |
| < 40% | `critical` | Crawl faible ‚ùå |

---

### 2. üï∑Ô∏è Top des crawlers actifs

**GET** `/seo-logs/kpi/top-crawlers`

Liste les bots qui crawlent le plus activement votre site.

#### Param√®tres

| Param | Type | D√©faut | Description |
|-------|------|--------|-------------|
| `timeWindow` | string | `72h` | Fen√™tre de temps |
| `limit` | number | `10` | Nombre de bots √† retourner (max 50) |

#### Exemple de requ√™te

```bash
curl http://localhost:3001/seo-logs/kpi/top-crawlers?timeWindow=7d&limit=5
```

#### Exemple de r√©ponse

```json
{
  "success": true,
  "data": {
    "timeWindow": "7d",
    "totalCrawlers": 5,
    "totalHits": 12450,
    "crawlers": [
      {
        "rank": 1,
        "bot": "googlebot",
        "hits": 7890,
        "percentage": 63.37
      },
      {
        "rank": 2,
        "bot": "bingbot",
        "hits": 2340,
        "percentage": 18.80
      },
      {
        "rank": 3,
        "bot": "yandexbot",
        "hits": 1120,
        "percentage": 9.00
      },
      {
        "rank": 4,
        "bot": "baiduspider",
        "hits": 650,
        "percentage": 5.22
      },
      {
        "rank": 5,
        "bot": "semrushbot",
        "hits": 450,
        "percentage": 3.61
      }
    ]
  }
}
```

---

### 3. üìÑ URLs les plus crawl√©es

**GET** `/seo-logs/kpi/most-crawled-urls`

Identifie les pages qui attirent le plus l'attention des crawlers.

#### Param√®tres

| Param | Type | D√©faut | Description |
|-------|------|--------|-------------|
| `timeWindow` | string | `72h` | Fen√™tre de temps |
| `limit` | number | `20` | Nombre d'URLs √† retourner |

#### Exemple de requ√™te

```bash
curl http://localhost:3001/seo-logs/kpi/most-crawled-urls?timeWindow=24h&limit=10
```

#### Exemple de r√©ponse

```json
{
  "success": true,
  "data": {
    "timeWindow": "24h",
    "totalUrls": 10,
    "urls": [
      {
        "rank": 1,
        "path": "/pieces/freins/renault/clio/1-5-dci",
        "crawls": 234
      },
      {
        "rank": 2,
        "path": "/pieces/plaquettes/peugeot/208/1-2-tce",
        "crawls": 189
      },
      {
        "rank": 3,
        "path": "/pieces/embrayage/volkswagen/golf/2-0-tdi",
        "crawls": 156
      }
    ]
  }
}
```

---

## Configuration requise

### Variables d'environnement

```bash
# URL de Loki (requis)
LOKI_URL=http://loki:3100

# URL du sitemap (requis pour crawl-rate)
SITEMAP_URL=https://automecanik.fr/sitemap.xml
```

### D√©pendances

- **Loki** : Doit √™tre accessible et contenir des logs
- **Vector** : Doit envoyer les logs Caddy vers Loki
- **Label Loki requis** : `job="caddy-access"`

---

## Cas d'usage

### 1. Monitoring SEO quotidien

```bash
# V√©rifier le taux de crawl sur 24h
curl http://localhost:3001/seo-logs/kpi/crawl-rate?timeWindow=24h | jq '.data.crawl.crawlRate'
```

**Alerte si < 60%** : Probl√®me potentiel de crawlabilit√©

### 2. Analyse comparative

```bash
# Comparer 7j vs 30j
curl http://localhost:3001/seo-logs/kpi/crawl-rate?timeWindow=7d
curl http://localhost:3001/seo-logs/kpi/crawl-rate?timeWindow=30d
```

**Baisse >20%** : Investigate robots.txt, sitemap, performances

### 3. Validation apr√®s changement

Apr√®s mise √† jour sitemap ou robots.txt :

```bash
# Baseline avant changement
curl http://localhost:3001/seo-logs/kpi/top-crawlers?timeWindow=72h > before.json

# Attendre 72h

# Mesurer l'impact
curl http://localhost:3001/seo-logs/kpi/top-crawlers?timeWindow=72h > after.json
diff before.json after.json
```

### 4. Dashboard Grafana

Cr√©er un dashboard avec panels :

```javascript
// Panel Crawl Rate (Gauge)
fetch('/seo-logs/kpi/crawl-rate?timeWindow=72h')
  .then(r => r.json())
  .then(d => d.data.crawl.crawlRate)

// Panel Top Bots (Table)
fetch('/seo-logs/kpi/top-crawlers?limit=10')
  .then(r => r.json())
  .then(d => d.data.crawlers)
```

---

## Troubleshooting

### Erreur: "Pas de donn√©es Loki"

**Cause:** Loki ne re√ßoit pas les logs ou label incorrect

**Solution:**
```bash
# V√©rifier que Vector envoie √† Loki
docker logs vector-seo-pipeline | grep loki

# Tester Loki directement
curl -G http://localhost:3100/loki/api/v1/query \
  --data-urlencode 'query={job="caddy-access"}' | jq
```

### Erreur: "Sitemap inaccessible"

**Cause:** URL du sitemap incorrecte ou site down

**Solution:**
```bash
# V√©rifier le sitemap
curl -I https://automecanik.fr/sitemap.xml

# Override temporaire
export SITEMAP_URL=https://example.com/sitemap.xml
```

### Crawl rate = 0%

**Causes possibles:**
1. Aucun bot n'a crawl√© (peu probable sur 72h)
2. Logs Loki vides (v√©rifier Vector)
3. Filtre `bot != ""` trop strict

**Debug:**
```bash
# Compter tous les hits (bots + humains)
curl -G http://localhost:3100/loki/api/v1/query \
  --data-urlencode 'query=count_over_time({job="caddy-access"} [72h])' | jq
```

---

## Performance

### Temps de r√©ponse typiques

| Endpoint | Fen√™tre | Temps |
|----------|---------|-------|
| crawl-rate | 72h | ~2-5s |
| top-crawlers | 7d | ~1-3s |
| most-crawled-urls | 24h | ~1-2s |

**Note:** Les requ√™tes LogQL peuvent √™tre lentes sur de gros volumes. Utiliser des fen√™tres de temps raisonnables.

### Optimisations

1. **Caching**: Impl√©menter un cache Redis pour les KPI (TTL 15min)
2. **Pre-aggregation**: Calculer les KPI via cron et stocker dans DB
3. **Indexation Loki**: V√©rifier la configuration des index Loki

---

## Roadmap

- [ ] Endpoint `/crawl-trends` : √âvolution du taux de crawl sur 30j
- [ ] Endpoint `/bot-behavior` : Patterns de crawl par bot (heures, jours)
- [ ] Endpoint `/sitemap-freshness` : URLs modifi√©es vs crawl√©es
- [ ] Webhook: Alertes si crawl rate < threshold
- [ ] Export CSV des KPIs pour reporting
