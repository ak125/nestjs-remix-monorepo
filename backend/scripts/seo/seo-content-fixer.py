#!/usr/bin/env python3
"""
üîß SEO CONTENT FIXER - Correction automatique des contenus SEO

V√©rifie et corrige le contenu de toutes les tables SEO:
- __seo_gamme_car (templates principaux)
- __seo_gamme_car_switch (switches de gamme)
- __seo_item_switch (switches d'items)

Usage:
    python seo-content-fixer.py                    # Audit uniquement (dry-run)
    python seo-content-fixer.py --fix              # Appliquer les corrections
    python seo-content-fixer.py --pg-id 402        # Cibler une gamme
    python seo-content-fixer.py --report out.json  # G√©n√©rer rapport JSON
    python seo-content-fixer.py --validate         # Tester via API apr√®s fix

Exemples:
    python seo-content-fixer.py --fix --validate   # Fix + test API
    python seo-content-fixer.py --pg-id 402 --fix  # Fix gamme 402 uniquement
"""

import argparse
import json
import sys
import requests
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

# Rich pour affichage console (optionnel mais recommand√©)
try:
    from rich.console import Console
    from rich.table import Table
    from rich.progress import Progress, SpinnerColumn, TextColumn
    from rich import print as rprint
    RICH_AVAILABLE = True
    console = Console()
except ImportError:
    RICH_AVAILABLE = False
    console = None

# Import des modules locaux
from lib.supabase_client import get_supabase_client
from lib.fix_rules import apply_fixes, detect_issues, get_stats_by_category, FIX_RULES

# ============================================
# CONFIGURATION
# ============================================

BACKUP_DIR = Path(__file__).parent / 'backups'
BACKEND_URL = "http://localhost:3000"

# ============================================
# TOUTES LES TABLES SEO + BLOG √Ä AUDITER (15 tables)
# ============================================

TABLES_CONFIG = {
    # ========== TABLES SEO PRINCIPALES ==========
    '__seo_gamme_car': {
        'id_field': 'sgc_pg_id',
        'text_fields': ['sgc_h1', 'sgc_content', 'sgc_preview', 'sgc_descrip', 'sgc_title'],
        'description': 'üìÑ Templates principaux (gamme+v√©hicule)',
        'priority': 1
    },
    '__seo_gamme': {
        'id_field': 'sg_pg_id',
        'text_fields': ['sg_h1', 'sg_content', 'sg_preview', 'sg_descrip', 'sg_title'],
        'description': 'üìÑ SEO g√©n√©rique gamme (sans v√©hicule)',
        'priority': 1
    },
    '__seo_marque': {
        'id_field': 'sm_marque_id',
        'text_fields': ['sm_h1', 'sm_content', 'sm_preview', 'sm_descrip', 'sm_title'],
        'description': 'üìÑ SEO par marque constructeur',
        'priority': 1
    },
    
    # ========== TABLES DE SWITCHES ==========
    '__seo_gamme_car_switch': {
        'id_field': 'sgcs_id',
        'pg_field': 'sgcs_pg_id',
        'text_fields': ['sgcs_content'],
        'description': 'üîÄ Switches gamme/v√©hicule',
        'priority': 2
    },
    '__seo_item_switch': {
        'id_field': 'sis_id',
        'pg_field': 'sis_pg_id',
        'text_fields': ['sis_content'],
        'description': 'üîÄ Switches d\'items',
        'priority': 2
    },
    '__seo_family_gamme_car_switch': {
        'id_field': 'sfgcs_id',
        'pg_field': 'sfgcs_pg_id',
        'text_fields': ['sfgcs_content'],
        'description': 'üîÄ Switches par famille',
        'priority': 2
    },
    '__seo_type_switch': {
        'id_field': 'sts_id',
        'text_fields': ['sts_content'],
        'description': 'üîÄ Switches par type',
        'priority': 2
    },
    
    # ========== TABLES SEO COMPL√âMENTAIRES ==========
    '__seo_gamme_car_conseil': {
        'id_field': 'sgcc_id',
        'pg_field': 'sgcc_pg_id',
        'text_fields': ['sgcc_content', 'sgcc_title'],
        'description': 'üí° Conseils par gamme',
        'priority': 3
    },
    '__seo_gamme_car_info': {
        'id_field': 'sgci_id',
        'pg_field': 'sgci_pg_id',
        'text_fields': ['sgci_content'],
        'description': '‚ÑπÔ∏è Infos additionnelles',
        'priority': 3
    },
    
    # ========== TABLES BLOG ==========
    '__blog_advice': {
        'id_field': 'ba_id',
        'text_fields': ['ba_title', 'ba_descrip', 'ba_h1', 'ba_h2', 'ba_preview', 'ba_content'],
        'description': 'üì∞ Articles conseils blog (principal)',
        'priority': 4
    },
    '__blog_guide': {
        'id_field': 'bg_id',
        'text_fields': ['bg_title', 'bg_descrip', 'bg_h1', 'bg_h2', 'bg_preview', 'bg_content'],
        'description': 'üìñ Guides blog',
        'priority': 4
    },
    '__blog_advice_h2': {
        'id_field': 'ba2_id',
        'text_fields': ['ba2_h2', 'ba2_content'],
        'description': 'üìù Sections H2 des articles blog',
        'priority': 5
    },
    '__blog_advice_h3': {
        'id_field': 'ba3_id',
        'text_fields': ['ba3_h3', 'ba3_content'],
        'description': 'üìù Sections H3 des articles blog',
        'priority': 5
    },
}

# ============================================
# CLASSE PRINCIPALE
# ============================================

class SeoContentFixer:
    def __init__(self, fix_mode: bool = False, pg_id: Optional[int] = None, validate: bool = False):
        self.fix_mode = fix_mode
        self.pg_id = pg_id
        self.validate = validate
        self.supabase = get_supabase_client()
        
        # Statistiques
        self.stats = {
            'tables_processed': 0,
            'tables_found': 0,
            'tables_missing': [],
            'records_scanned': 0,
            'issues_found': 0,
            'issues_fixed': 0,
            'by_category': {},
            'by_table': {},
            'errors': [],
            'validation_results': []
        }
        
        # Backup des donn√©es originales
        self.backup_data = {}
    
    def log(self, msg: str, style: str = None):
        """Affiche un message (avec Rich si disponible)"""
        if RICH_AVAILABLE and style:
            console.print(msg, style=style)
        else:
            print(msg)
    
    def log_success(self, msg: str):
        self.log(f"‚úÖ {msg}", "green")
    
    def log_warning(self, msg: str):
        self.log(f"‚ö†Ô∏è  {msg}", "yellow")
    
    def log_error(self, msg: str):
        self.log(f"‚ùå {msg}", "red bold")
    
    def log_info(self, msg: str):
        self.log(f"‚ÑπÔ∏è  {msg}", "blue")

    # ============================================
    # V√âRIFICATION DES TABLES
    # ============================================
    
    def check_table_exists(self, table_name: str) -> bool:
        """V√©rifie si une table existe dans Supabase"""
        try:
            result = self.supabase.table(table_name).select('*').limit(1).execute()
            return True
        except Exception as e:
            if 'does not exist' in str(e) or '42P01' in str(e) or 'relation' in str(e).lower():
                return False
            # Autre erreur, on consid√®re que la table existe
            return True

    # ============================================
    # BACKUP
    # ============================================
    
    def create_backup(self, table_name: str, data: List[Dict]) -> Path:
        """Sauvegarde les donn√©es originales en JSON"""
        BACKUP_DIR.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y-%m-%d_%Hh%M')
        filename = f"{timestamp}_{table_name}.json"
        filepath = BACKUP_DIR / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump({
                'table': table_name,
                'timestamp': timestamp,
                'count': len(data),
                'data': data
            }, f, ensure_ascii=False, indent=2)
        
        self.log_info(f"Backup cr√©√©: {filepath.name} ({len(data)} enregistrements)")
        return filepath

    # ============================================
    # TRAITEMENT DES TABLES
    # ============================================
    
    def process_table(self, table_name: str) -> Dict[str, Any]:
        """Traite une table SEO compl√®te"""
        config = TABLES_CONFIG[table_name]
        self.log(f"\n{'='*60}", "cyan")
        self.log(f"üìã {table_name} - {config['description']}", "cyan bold")
        self.log('='*60, "cyan")
        
        # V√©rifier si la table existe
        if not self.check_table_exists(table_name):
            self.log_warning(f"Table non trouv√©e dans Supabase - ignor√©e")
            self.stats['tables_missing'].append(table_name)
            return {'scanned': 0, 'issues': 0, 'fixed': 0, 'exists': False}
        
        self.stats['tables_found'] += 1
        
        # R√©cup√©rer les donn√©es avec pagination (Supabase limite √† 1000 par d√©faut)
        try:
            all_records = []
            page_size = 1000
            offset = 0
            
            while True:
                query = self.supabase.table(table_name).select('*').range(offset, offset + page_size - 1)
                
                # Filtrer par pg_id si sp√©cifi√©
                if self.pg_id:
                    pg_field = config.get('pg_field', config['id_field'])
                    query = query.eq(pg_field, self.pg_id)
                
                result = query.execute()
                batch = result.data or []
                
                if not batch:
                    break
                    
                all_records.extend(batch)
                
                if len(batch) < page_size:
                    break
                    
                offset += page_size
                
            records = all_records
        except Exception as e:
            self.log_error(f"Erreur lecture: {str(e)}")
            self.stats['errors'].append(f"{table_name}: {str(e)}")
            return {'scanned': 0, 'issues': 0, 'fixed': 0, 'exists': True, 'error': str(e)}
        
        if not records:
            self.log_warning(f"Aucun enregistrement trouv√©")
            return {'scanned': 0, 'issues': 0, 'fixed': 0, 'exists': True}
        
        self.log_info(f"üìä {len(records)} enregistrements √† analyser")
        
        # Backup avant modification
        if self.fix_mode and records:
            self.create_backup(table_name, records)
        
        # Traitement
        table_stats = {'scanned': 0, 'issues': 0, 'fixed': 0, 'exists': True, 'details': []}
        id_field = config['id_field']
        text_fields = config['text_fields']
        
        for record in records:
            table_stats['scanned'] += 1
            record_id = record.get(id_field)
            record_issues = []
            updates = {}
            
            # Analyser chaque champ texte
            for field in text_fields:
                text = record.get(field)
                if not text:
                    continue
                
                # D√©tecter les probl√®mes
                issues = detect_issues(text, field)
                fixable_issues = [i for i in issues if i.get('can_fix')]
                
                if fixable_issues:
                    record_issues.extend(fixable_issues)
                    
                    # Appliquer corrections si mode fix
                    if self.fix_mode:
                        fixed_text, applied = apply_fixes(text)
                        if fixed_text != text:
                            updates[field] = fixed_text
            
            # Comptabiliser
            if record_issues:
                table_stats['issues'] += len(record_issues)
                table_stats['details'].append({
                    'id': record_id,
                    'issues': [i['desc'] for i in record_issues]
                })
                
                # Afficher les 10 premiers
                if len(table_stats['details']) <= 10:
                    self.log_warning(f"  ID {record_id}: {len(record_issues)} probl√®me(s)")
                    for issue in record_issues[:3]:
                        print(f"      ‚Üí {issue['desc']}")
            
            # Appliquer les updates
            if self.fix_mode and updates:
                try:
                    self.supabase.table(table_name).update(updates).eq(id_field, record_id).execute()
                    table_stats['fixed'] += len(updates)
                except Exception as e:
                    self.stats['errors'].append(f"{table_name} ID {record_id}: {str(e)}")
        
        # R√©sum√©
        if table_stats['details'] and len(table_stats['details']) > 10:
            self.log(f"  ... et {len(table_stats['details']) - 10} autres enregistrements avec probl√®mes")
        
        self.log_info(f"üìà R√©sultat: {table_stats['issues']} probl√®mes trouv√©s, {table_stats['fixed']} corrig√©s")
        
        return table_stats

    # ============================================
    # VALIDATION API
    # ============================================
    
    def validate_api(self, sample_pg_ids: List[int] = None):
        """Teste le rendu API apr√®s corrections"""
        self.log(f"\n{'='*60}", "magenta")
        self.log("üß™ VALIDATION API", "magenta bold")
        self.log('='*60, "magenta")
        
        # R√©cup√©rer des pg_id √† tester
        if not sample_pg_ids:
            result = self.supabase.table('__seo_gamme_car').select('sgc_pg_id').limit(10).execute()
            sample_pg_ids = [r['sgc_pg_id'] for r in (result.data or [])]
        
        if not sample_pg_ids:
            self.log_warning("Aucune gamme √† tester")
            return
        
        self.log_info(f"Test de {len(sample_pg_ids)} gammes via API...")
        
        # Type_id par d√©faut (peut √™tre param√©tr√©)
        type_id = 27534
        errors = []
        success = 0
        
        for pg_id in sample_pg_ids:
            try:
                response = requests.post(
                    f"{BACKEND_URL}/api/catalog/gammes/{pg_id}/seo",
                    json={"type_id": type_id},
                    timeout=10
                )
                
                if response.status_code == 200:
                    data = response.json()
                    content = data.get('content', '')
                    
                    # V√©rifier probl√®mes r√©siduels
                    issues = []
                    if ' .' in content:
                        issues.append('espace avant point')
                    if ',,' in content:
                        issues.append('double virgule')
                    if 'qui doit √™tre' in content.lower():
                        issues.append('grammaire')
                    
                    if issues:
                        errors.append(f"pg={pg_id}: {', '.join(issues)}")
                        self.log_warning(f"  Gamme {pg_id}: {', '.join(issues)}")
                    else:
                        success += 1
                        self.log_success(f"  Gamme {pg_id}: OK")
                else:
                    errors.append(f"pg={pg_id}: HTTP {response.status_code}")
                    
            except requests.exceptions.RequestException as e:
                errors.append(f"pg={pg_id}: {str(e)}")
        
        self.stats['validation_results'] = {
            'tested': len(sample_pg_ids),
            'success': success,
            'errors': errors
        }
        
        self.log_info(f"üìà Validation: {success}/{len(sample_pg_ids)} gammes OK")
        if errors:
            self.log_error(f"   {len(errors)} gamme(s) avec probl√®mes r√©siduels")

    # ============================================
    # FLUSH CACHE REDIS
    # ============================================
    
    def flush_redis_cache(self):
        """Vide le cache Redis apr√®s corrections"""
        import subprocess
        try:
            result = subprocess.run(
                ['docker', 'exec', 'redis-dev', 'redis-cli', 'FLUSHDB'],
                capture_output=True, text=True, timeout=10
            )
            if result.returncode == 0:
                self.log_success("Cache Redis vid√©")
            else:
                self.log_warning(f"Erreur flush Redis: {result.stderr}")
        except Exception as e:
            self.log_warning(f"Impossible de vider le cache Redis: {e}")

    # ============================================
    # EX√âCUTION PRINCIPALE
    # ============================================
    
    def run(self) -> Dict[str, Any]:
        """Ex√©cute l'audit/correction complet"""
        start_time = datetime.now()
        
        self.log("\n" + "="*60, "bold")
        mode_str = "üîß MODE CORRECTION" if self.fix_mode else "üîç MODE AUDIT (dry-run)"
        self.log(f"  SEO CONTENT FIXER - {mode_str}", "bold")
        if self.pg_id:
            self.log(f"  üìå Ciblage: pg_id = {self.pg_id}", "bold")
        self.log(f"  üìã Tables configur√©es: {len(TABLES_CONFIG)}", "bold")
        self.log("="*60 + "\n", "bold")
        
        # Trier les tables par priorit√©
        sorted_tables = sorted(TABLES_CONFIG.items(), key=lambda x: x[1].get('priority', 99))
        
        # Traiter chaque table
        for table_name, config in sorted_tables:
            table_stats = self.process_table(table_name)
            self.stats['tables_processed'] += 1
            self.stats['records_scanned'] += table_stats['scanned']
            self.stats['issues_found'] += table_stats['issues']
            self.stats['issues_fixed'] += table_stats['fixed']
            self.stats['by_table'][table_name] = table_stats
        
        # Flush cache si corrections appliqu√©es
        if self.fix_mode and self.stats['issues_fixed'] > 0:
            self.flush_redis_cache()
        
        # Validation API si demand√©e
        if self.validate:
            self.validate_api()
        
        # Dur√©e
        duration = (datetime.now() - start_time).total_seconds()
        self.stats['duration_seconds'] = round(duration, 2)
        
        # R√©sum√© final
        self.print_summary()
        
        return self.stats
    
    def print_summary(self):
        """Affiche le r√©sum√© final"""
        self.log("\n" + "="*60, "bold")
        self.log("  üìä R√âSUM√â COMPLET", "bold")
        self.log("="*60, "bold")
        
        stats = self.stats
        
        if RICH_AVAILABLE:
            table = Table(show_header=True, header_style="bold cyan")
            table.add_column("M√©trique", style="dim")
            table.add_column("Valeur", justify="right")
            
            table.add_row("Tables configur√©es", str(len(TABLES_CONFIG)))
            table.add_row("Tables trouv√©es", str(stats['tables_found']))
            table.add_row("Tables manquantes", str(len(stats['tables_missing'])))
            table.add_row("Enregistrements scann√©s", str(stats['records_scanned']))
            table.add_row("Probl√®mes trouv√©s", str(stats['issues_found']))
            table.add_row("Probl√®mes corrig√©s", str(stats['issues_fixed']))
            table.add_row("Dur√©e", f"{stats['duration_seconds']}s")
            
            console.print(table)
            
            # D√©tails par table
            if stats['by_table']:
                self.log("\nüìã D√âTAILS PAR TABLE:", "bold")
                detail_table = Table(show_header=True, header_style="bold blue")
                detail_table.add_column("Table")
                detail_table.add_column("Scann√©s", justify="right")
                detail_table.add_column("Probl√®mes", justify="right")
                detail_table.add_column("Corrig√©s", justify="right")
                detail_table.add_column("Status")
                
                for tbl, tbl_stats in stats['by_table'].items():
                    status = "‚úÖ" if tbl_stats.get('exists', True) else "‚ùå Non trouv√©e"
                    if tbl_stats.get('error'):
                        status = "‚ö†Ô∏è Erreur"
                    detail_table.add_row(
                        tbl,
                        str(tbl_stats['scanned']),
                        str(tbl_stats['issues']),
                        str(tbl_stats['fixed']),
                        status
                    )
                console.print(detail_table)
        else:
            print(f"  Tables configur√©es:      {len(TABLES_CONFIG)}")
            print(f"  Tables trouv√©es:         {stats['tables_found']}")
            print(f"  Tables manquantes:       {len(stats['tables_missing'])}")
            print(f"  Enregistrements scann√©s: {stats['records_scanned']}")
            print(f"  Probl√®mes trouv√©s:       {stats['issues_found']}")
            print(f"  Probl√®mes corrig√©s:      {stats['issues_fixed']}")
            print(f"  Dur√©e:                   {stats['duration_seconds']}s")
        
        if stats['tables_missing']:
            self.log(f"\n‚ö†Ô∏è  Tables non trouv√©es: {', '.join(stats['tables_missing'])}", "yellow")
        
        if stats['errors']:
            self.log_error(f"\n‚ùå {len(stats['errors'])} erreur(s) lors du traitement")
            for err in stats['errors'][:5]:
                print(f"   ‚Ä¢ {err}")
        
        if not self.fix_mode and stats['issues_found'] > 0:
            self.log("\nüí° Pour appliquer les corrections: python seo-content-fixer.py --fix", "yellow")


def save_report(stats: Dict, filepath: Path):
    """Sauvegarde le rapport en JSON"""
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2, default=str)
    print(f"üìÑ Rapport sauvegard√©: {filepath}")


# ============================================
# POINT D'ENTR√âE
# ============================================

def main():
    parser = argparse.ArgumentParser(
        description='üîß SEO Content Fixer - Correction automatique de TOUTES les tables SEO + BLOG',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
üìã TABLES AUDIT√âES (13 au total):

  üîµ TABLES SEO:
  ‚Ä¢ __seo_gamme_car           Templates principaux (gamme+v√©hicule)
  ‚Ä¢ __seo_gamme               SEO g√©n√©rique gamme
  ‚Ä¢ __seo_marque              SEO par marque constructeur
  ‚Ä¢ __seo_gamme_car_switch    Switches gamme/v√©hicule
  ‚Ä¢ __seo_item_switch         Switches d'items
  ‚Ä¢ __seo_family_gamme_car_switch  Switches par famille
  ‚Ä¢ __seo_type_switch         Switches par type
  ‚Ä¢ __seo_gamme_car_conseil   Conseils par gamme
  ‚Ä¢ __seo_gamme_car_info      Infos additionnelles

  üü¢ TABLES BLOG:
  ‚Ä¢ __blog_advice             Articles conseils (85)
  ‚Ä¢ __blog_guide              Guides blog (1)
  ‚Ä¢ __blog_advice_h2          Sections H2 (451)
  ‚Ä¢ __blog_advice_h3          Sections H3 (200)

Exemples:
  python seo-content-fixer.py                    # Audit seul
  python seo-content-fixer.py --fix              # Appliquer corrections
  python seo-content-fixer.py --fix --validate   # Fix + test API
  python seo-content-fixer.py --pg-id 402 --fix  # Fix gamme 402
        """
    )
    
    parser.add_argument('--fix', action='store_true',
                        help='Appliquer les corrections (sinon audit seul)')
    parser.add_argument('--pg-id', type=int, metavar='ID',
                        help='Cibler une gamme sp√©cifique par son pg_id')
    parser.add_argument('--validate', action='store_true',
                        help='Tester le rendu API apr√®s corrections')
    parser.add_argument('--report', type=str, metavar='FILE',
                        help='Sauvegarder le rapport en JSON')
    parser.add_argument('--rules', action='store_true',
                        help='Afficher les r√®gles de correction')
    parser.add_argument('--tables', action='store_true',
                        help='Afficher la liste des tables audit√©es')
    
    args = parser.parse_args()
    
    # Afficher les tables si demand√©
    if args.tables:
        print("\nüìã TABLES SEO AUDIT√âES (9 tables)\n")
        for i, (name, config) in enumerate(TABLES_CONFIG.items(), 1):
            print(f"  {i:2}. {name:35} {config['description']}")
        print()
        return
    
    # Afficher les r√®gles si demand√©
    if args.rules:
        print("\nüìè R√àGLES DE CORRECTION\n")
        for i, rule in enumerate(FIX_RULES, 1):
            print(f"  {i:2}. [{rule['category']:12}] {rule['desc']}")
        print()
        return
    
    # Ex√©cuter
    try:
        fixer = SeoContentFixer(
            fix_mode=args.fix,
            pg_id=args.pg_id,
            validate=args.validate
        )
        stats = fixer.run()
        
        # Sauvegarder rapport si demand√©
        if args.report:
            save_report(stats, Path(args.report))
        
        # Code de sortie
        sys.exit(0 if stats['issues_fixed'] > 0 or stats['issues_found'] == 0 else 1)
        
    except Exception as e:
        print(f"‚ùå Erreur fatale: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()