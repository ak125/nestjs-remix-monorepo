# Installation et Configuration des Providers IA GRATUITS

## ðŸŽ¯ Vous avez 3 options GRATUITES sans OpenAI !

---

## Option 1: Ollama (LOCAL - 100% GRATUIT) ðŸŒŸ RECOMMANDÃ‰

**Avantages:**
- âœ… Totalement GRATUIT et illimitÃ©
- âœ… Fonctionne hors ligne
- âœ… Aucune limite de tokens
- âœ… DonnÃ©es privÃ©es (tout reste sur votre machine)
- âœ… TrÃ¨s rapide une fois installÃ©

### Installation

#### Sur Linux (dans votre dev container)
```bash
# Installer Ollama
curl -fsSL https://ollama.com/install.sh | sh

# DÃ©marrer le service
ollama serve &

# TÃ©lÃ©charger un modÃ¨le (choisir selon vos besoins)
# Petit et rapide (2GB)
ollama pull llama3.2:3b

# Ã‰quilibrÃ© (4.7GB) - RECOMMANDÃ‰
ollama pull llama3.1:8b

# Puissant pour du contenu complexe (40GB)
ollama pull llama3.1:70b

# ModÃ¨le franÃ§ais optimisÃ© (4GB)
ollama pull vigogne:7b-instruct
```

#### Configuration dans .env
```bash
AI_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b  # ou llama3.2:3b pour plus rapide
```

#### Test
```bash
# Tester Ollama
curl http://localhost:11434/api/tags

# GÃ©nÃ©rer du texte
ollama run llama3.1:8b "Ã‰cris une description pour une vanne papillon"
```

---

## Option 2: Groq (API GRATUITE - ULTRA RAPIDE) âš¡

**Avantages:**
- âœ… API 100% GRATUITE
- âœ… 14,400 requÃªtes/jour gratuites
- âœ… Le plus RAPIDE (jusqu'Ã  500 tokens/seconde!)
- âœ… ModÃ¨les puissants (Llama 3 70B)
- âœ… Parfait pour la production

### Installation

#### 1. CrÃ©er un compte gratuit
```bash
# Aller sur https://console.groq.com
# CrÃ©er un compte (GitHub OAuth disponible)
# GÃ©nÃ©rer une clÃ© API (gratuite!)
```

#### 2. Configuration dans .env
```bash
AI_PROVIDER=groq
GROQ_API_KEY=gsk_votre_clÃ©_ici
GROQ_MODEL=llama3-70b-8192  # ou mixtral-8x7b-32768
```

#### ModÃ¨les disponibles (tous GRATUITS):
- `llama3-70b-8192` - Le plus puissant (recommandÃ©)
- `llama3-8b-8192` - Rapide et efficace
- `mixtral-8x7b-32768` - Bon pour du contenu long
- `gemma-7b-it` - Alternative lÃ©gÃ¨re

#### Limites gratuites:
- 14,400 requÃªtes/jour
- 6,000 requÃªtes/minute
- Largement suffisant pour 99% des usages!

---

## Option 3: HuggingFace (API GRATUITE) ðŸ¤—

**Avantages:**
- âœ… API GRATUITE
- âœ… AccÃ¨s Ã  des milliers de modÃ¨les
- âœ… Bonne qualitÃ© de gÃ©nÃ©ration
- âš ï¸ Plus lent que Groq

### Installation

#### 1. CrÃ©er un compte
```bash
# Aller sur https://huggingface.co
# CrÃ©er un compte gratuit
# Settings > Access Tokens > New Token
```

#### 2. Configuration dans .env
```bash
AI_PROVIDER=huggingface
HUGGINGFACE_API_KEY=hf_votre_clÃ©_ici
HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.2
```

#### ModÃ¨les recommandÃ©s (tous GRATUITS):
- `mistralai/Mistral-7B-Instruct-v0.2` - Excellent rapport qualitÃ©/vitesse
- `meta-llama/Llama-2-7b-chat-hf` - Stable et fiable
- `tiiuae/falcon-7b-instruct` - Alternative intÃ©ressante
- `bigscience/bloomz-7b1` - Bon pour le franÃ§ais

---

## Auto-DÃ©tection (RECOMMANDÃ‰ pour Production)

Le systÃ¨me peut auto-dÃ©tecter le meilleur provider disponible:

```bash
# Dans .env
AI_PROVIDER=auto

# Le systÃ¨me essaiera dans cet ordre:
# 1. Ollama (local)
# 2. Groq (si GROQ_API_KEY existe)
# 3. HuggingFace (si HUGGINGFACE_API_KEY existe)
# 4. OpenAI (si OPENAI_API_KEY existe)
```

---

## Comparaison des Options

| Provider | CoÃ»t | Vitesse | QualitÃ© | Hors ligne | Setup |
|----------|------|---------|---------|------------|-------|
| **Ollama** | ðŸ’¯ Gratuit | âš¡âš¡ Rapide | â­â­â­â­ | âœ… Oui | 5 min |
| **Groq** | ðŸ’¯ Gratuit | âš¡âš¡âš¡ Ultra | â­â­â­â­â­ | âŒ Non | 2 min |
| **HuggingFace** | ðŸ’¯ Gratuit | âš¡ Moyen | â­â­â­ | âŒ Non | 3 min |
| OpenAI | ðŸ’° Payant | âš¡âš¡ Rapide | â­â­â­â­â­ | âŒ Non | 2 min |

---

## Configuration RecommandÃ©e selon Usage

### Pour DÃ©veloppement Local
```bash
AI_PROVIDER=ollama
OLLAMA_MODEL=llama3.2:3b  # Rapide et lÃ©ger
```

### Pour Production avec Budget
```bash
AI_PROVIDER=groq
GROQ_API_KEY=gsk_...
GROQ_MODEL=llama3-70b-8192  # Meilleure qualitÃ© gratuite
```

### Pour Maximum de RÃ©silience
```bash
AI_PROVIDER=auto
GROQ_API_KEY=gsk_...           # Primary
HUGGINGFACE_API_KEY=hf_...     # Backup
# + Ollama installÃ© en local      # Fallback
```

---

## Installation Rapide ComplÃ¨te

### Script d'installation tout-en-un

```bash
#!/bin/bash

echo "ðŸ¤– Installation des providers IA GRATUITS"

# 1. Installer Ollama (local)
echo "ðŸ“¦ Installation d'Ollama..."
curl -fsSL https://ollama.com/install.sh | sh
ollama serve > /dev/null 2>&1 &
sleep 2
ollama pull llama3.1:8b

# 2. Configurer le .env
cat >> .env << EOF

# ðŸ¤– AI CONTENT GENERATION
AI_PROVIDER=auto

# Ollama (local - gratuit illimitÃ©)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# Groq (API gratuite - ultra rapide)
# Obtenir une clÃ© sur: https://console.groq.com
GROQ_API_KEY=
GROQ_MODEL=llama3-70b-8192

# HuggingFace (API gratuite - backup)
# Obtenir une clÃ© sur: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=
HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.2
EOF

echo "âœ… Configuration terminÃ©e!"
echo ""
echo "ðŸ“ Prochaines Ã©tapes:"
echo "1. Obtenir une clÃ© Groq (gratuite): https://console.groq.com"
echo "2. Ajouter GROQ_API_KEY dans .env"
echo "3. DÃ©marrer le backend: npm run dev"
echo ""
echo "ðŸŽ¯ Vous pouvez dÃ©jÃ  utiliser Ollama en local!"
```

Enregistrez ce script dans `install-ai-providers.sh` et exÃ©cutez:

```bash
chmod +x install-ai-providers.sh
./install-ai-providers.sh
```

---

## Test de Fonctionnement

```bash
# Test Ollama
curl http://localhost:11434/api/tags

# Test de gÃ©nÃ©ration avec votre API
curl -X POST http://localhost:5001/api/ai-content/generate/product-description \
  -H "Content-Type: application/json" \
  -d '{
    "productName": "Vanne papillon motorisÃ©e DN50",
    "features": ["Corps fonte", "Motorisation 24V"],
    "tone": "professional",
    "length": "medium"
  }'
```

---

## DÃ©pannage

### Ollama ne dÃ©marre pas
```bash
# VÃ©rifier le statut
ps aux | grep ollama

# RedÃ©marrer
pkill ollama
ollama serve &
```

### Groq retourne une erreur
```bash
# VÃ©rifier votre clÃ© API
curl https://api.groq.com/openai/v1/models \
  -H "Authorization: Bearer $GROQ_API_KEY"
```

### HuggingFace est lent
C'est normal, le modÃ¨le "chauffe" au premier appel. Patience!

---

## ðŸŽ‰ Conclusion

**Vous n'avez AUCUNE excuse pour ne pas avoir de l'IA maintenant!**

1. **Quick Start**: Installez Ollama (5 minutes)
2. **Production**: CrÃ©ez un compte Groq (2 minutes)
3. **Redondance**: Ajoutez HuggingFace en backup

**Tout est GRATUIT et ILLIMITÃ‰!** ðŸš€
