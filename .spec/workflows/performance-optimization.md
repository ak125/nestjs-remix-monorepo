---
title: "Workflow: Performance Optimization"
status: approved
version: 1.0.0
authors: [Backend Team, DevOps]
created: 2025-11-17
updated: 2025-11-17
relates-to:
  - ../architecture/003-cache-redis-multi-levels.md
  - ../../PERFORMANCE-OPTIMIZATIONS.md
tags: [workflow, performance, monitoring, optimization]
---

# Workflow: Performance Optimization

## üìù Overview

Ce workflow d√©crit le processus complet pour **diagnostiquer, corriger et valider** les probl√®mes de performance dans l'application. Il a √©t√© formalis√© suite √† l'incident du 17 novembre 2025 o√π la homepage prenait 15-20s √† charger.

**Objectifs** :
- D√©tection rapide des probl√®mes performance (< 30min)
- Diagnostic structur√© avec preuves mesurables
- Impl√©mentation prioris√©e (quick wins first)
- Validation avec m√©triques avant/apr√®s
- Documentation pour r√©utilisabilit√©

## üéØ Quand utiliser ce workflow

- ‚úÖ Page lente signal√©e (> 3s load time)
- ‚úÖ API endpoint > 1s response time
- ‚úÖ Queries DB > 500ms
- ‚úÖ Cache hit rate < 50%
- ‚úÖ Alertes Prometheus/Grafana
- ‚úÖ Plaintes utilisateurs support

## üîÑ Phases du workflow

```
1. D√©tection ‚Üí 2. Diagnostic ‚Üí 3. Priorisation ‚Üí 4. Impl√©mentation ‚Üí 5. Validation ‚Üí 6. Documentation
     ‚Üì              ‚Üì              ‚Üì                  ‚Üì                   ‚Üì               ‚Üì
  Alertes       Analyse       Quick wins         Correctifs          Tests          Post-mortem
  Logs          Metrics       vs Long-term       + Cache             A/B            ADR/Docs
  Support       Traces        Impact matrix      + Indexes           Monitoring     Learnings
```

---

## Phase 1: D√©tection üîç

### Objectif
Confirmer et quantifier le probl√®me de performance

### Actions

#### 1.1. Collecter les sympt√¥mes
- [ ] **Logs application** : `tail -n 500 logs/nest.log > incident.log`
- [ ] **M√©triques utilisateur** : Temps de chargement report√©
- [ ] **URL/Endpoint** : Page ou API affect√©e
- [ ] **Contexte** : Heure, fr√©quence, utilisateurs impact√©s

#### 1.2. Reproduire le probl√®me
```bash
# Test manuel
curl -w "@curl-format.txt" -o /dev/null -s https://app.com/page

# Ou avec outil diagnostic
node backend/diagnose-performance.js < logs/nest.log
```

#### 1.3. Crit√®res de gravit√©

| Niveau | Crit√®re | Action |
|--------|---------|--------|
| üî¥ **P0 Critical** | Page > 10s, Production down | Incident immediat, all hands |
| üü† **P1 High** | Page 5-10s, API > 2s | Fix dans 24h |
| üü° **P2 Medium** | Page 3-5s, API 1-2s | Fix dans 1 semaine |
| üü¢ **P3 Low** | Page < 3s, optimisation progressive | Backlog |

### Outputs
- ‚úÖ Fichier logs incident (`incident-YYYY-MM-DD.log`)
- ‚úÖ Priorit√© assign√©e (P0-P3)
- ‚úÖ Owner responsable diagnostic

**Dur√©e estim√©e** : 15-30 minutes

---

## Phase 2: Diagnostic üî¨

### Objectif
Identifier la cause racine avec preuves mesurables

### Actions

#### 2.1. Analyser les logs structur√©s

```bash
# Utiliser l'outil diagnostic
tail -f logs/nest.log | node backend/diagnose-performance.js

# Chercher patterns:
# - Requ√™tes dupliqu√©es (>3 appels identiques)
# - Queries lentes (>1000ms)
# - Cache misses r√©p√©t√©s
# - Erreurs silencieuses
```

**Outputs attendus** :
```
=== TOP 10 ENDPOINTS (par nombre d'appels) ===
/api/catalog/equipementiers : 6 appels
/api/catalog/gammes/hierarchy : 6 appels

=== REQU√äTES DUPLIQU√âES ===
GET /api/catalog/equipementiers - 6 appels en 2.3s

=== QUERIES LENTES (>1000ms) ===
SELECT * FROM pieces WHERE ... - 4123ms
```

#### 2.2. Profiler les requ√™tes DB

```sql
-- Activer logging queries lentes (Supabase Dashboard)
ALTER DATABASE postgres SET log_min_duration_statement = 1000;

-- Analyser explain plans
EXPLAIN ANALYZE SELECT * FROM pieces WHERE rtp_type_id = 1;
```

**Signaux d'alerte** :
- ‚ùå Seq Scan au lieu d'Index Scan
- ‚ùå Nested Loop avec millions de rows
- ‚ùå Query cost > 10000

#### 2.3. Tracer les appels r√©seau

```typescript
// Ajouter timing logs temporaires
const start = Date.now();
const result = await this.service.getData();
this.logger.debug(`getData took ${Date.now() - start}ms`);
```

#### 2.4. V√©rifier le cache

```bash
# Stats Redis
redis-cli INFO stats

# V√©rifier TTL keys
redis-cli --scan --pattern "catalog:*" | head -20

# Hit rate
# (keyspace_hits / (keyspace_hits + keyspace_misses)) * 100
```

### Checklist diagnostic

- [ ] **Frontend** : useEffect loops, fetches non-dedup√©s
- [ ] **Backend** : Queries N+1, pas de pagination
- [ ] **Database** : Indexes manquants, queries lentes
- [ ] **Cache** : TTL trop court, pas de cache
- [ ] **R√©seau** : Latence externe, CDN slow
- [ ] **Code** : Loops imbriqu√©s, mauvais algo

### Outputs
- ‚úÖ Cause racine identifi√©e (ex: "6 appels dupliqu√©s √©quipementiers")
- ‚úÖ M√©triques baseline (temps avant fix)
- ‚úÖ Reproduction steps document√©s

**Dur√©e estim√©e** : 30-60 minutes

---

## Phase 3: Priorisation üìä

### Objectif
Identifier quick wins vs optimisations long-terme

### Impact Matrix

| Solution | Effort | Impact | ROI | Priorit√© |
|----------|--------|--------|-----|----------|
| **Cache Redis TTL 1h** | 1h | -83% | üü¢ Tr√®s haut | P0 |
| **Parall√©liser queries** | 2h | -70% | üü¢ Tr√®s haut | P0 |
| **Indexes DB** | 30min | -60% | üü¢ Tr√®s haut | P1 |
| **Fix useEffect frontend** | 1h | -83% | üü¢ Tr√®s haut | P1 |
| **React Query dedupe** | 3h | -50% | üü° Moyen | P2 |
| **CDN logos** | 4h | -20% | üü° Moyen | P2 |
| **Connection pool** | 1h | -10% | üü† Faible | P3 |

### Strat√©gie recommand√©e

**Phase imm√©diate (< 4h)** :
1. Cache Redis (1h) ‚Üí -83%
2. Parall√©lisation (2h) ‚Üí -70%
3. Indexes DB (30min) ‚Üí -60%

**Phase court-terme (< 1 semaine)** :
4. Fix frontend loops (1h)
5. React Query (3h)

**Phase long-terme (backlog)** :
6. CDN, connection pool, monitoring avanc√©

### Outputs
- ‚úÖ Liste solutions prioris√©es (P0/P1/P2/P3)
- ‚úÖ Estimation effort/impact par solution
- ‚úÖ Plan d'action avec timeline

**Dur√©e estim√©e** : 15-30 minutes

---

## Phase 4: Impl√©mentation üõ†Ô∏è

### Objectif
Appliquer les correctifs avec tests progressifs

### Bonnes pratiques

#### 4.1. Cr√©er une branche d√©di√©e
```bash
git checkout -b perf/fix-homepage-load-time
```

#### 4.2. Impl√©menter par ordre de priorit√©

**Quick Win 1: Cache Redis**
```typescript
// Avant
const data = await this.service.getEquipementiers();
return data;

// Apr√®s (1h dev)
const cacheKey = 'catalog:equipementiers:all';
const cached = await this.cacheService.get(cacheKey);
if (cached) return JSON.parse(cached);

const data = await this.service.getEquipementiers();
await this.cacheService.set(cacheKey, JSON.stringify(data), 3600);
return data;
```

**Quick Win 2: Parall√©lisation**
```typescript
// Avant (s√©quentiel 5s)
const marque = await supabase.from('auto_marque').select('*').eq('am_id', marqueId);
const modele = await supabase.from('auto_modele').select('*').eq('amod_id', modeleId);

// Apr√®s (parall√®le 1.5s)
const [marqueResult, modeleResult] = await Promise.all([
  marqueId ? supabase.from('auto_marque').select('*').eq('am_id', marqueId) : null,
  modeleId ? supabase.from('auto_modele').select('*').eq('amod_id', modeleId) : null
]);
```

**Quick Win 3: Indexes DB**
```sql
-- Supabase Dashboard > SQL Editor
CREATE INDEX CONCURRENTLY idx_rtp_type_pg_display 
ON pieces_relation_type(rtp_type_id, rtp_pg_id, rtp_display)
WHERE rtp_display = 1;

CREATE INDEX CONCURRENTLY idx_pri_piece_dispo 
ON pieces_price(pri_piece_id, pri_dispo)
WHERE pri_dispo = 1;
```

#### 4.3. Tester localement

```bash
# Compilation TypeScript
npm run build

# Tests unitaires
npm run test

# Test manuel endpoint
curl -w "@curl-format.txt" http://localhost:3001/api/catalog/equipementiers
```

#### 4.4. V√©rifier pas de r√©gression

```bash
# Comparer output avant/apr√®s
node backend/compare-outputs.js --endpoint /api/catalog/equipementiers

# Lancer tous les tests
npm run test:e2e
```

### Checklist impl√©mentation

- [ ] Code compil√© sans erreurs
- [ ] Tests unitaires passent
- [ ] Tests E2E passent
- [ ] Logs monitoring ajout√©s
- [ ] Documentation inline (JSDoc)
- [ ] Pas de credentials hardcod√©s
- [ ] Rollback plan d√©fini

### Outputs
- ‚úÖ Code impl√©ment√© et test√©
- ‚úÖ PR cr√©√©e avec description d√©taill√©e
- ‚úÖ Tests automatis√©s ajout√©s

**Dur√©e estim√©e** : 2-8 heures (selon complexit√©)

---

## Phase 5: Validation ‚úÖ

### Objectif
Mesurer gains r√©els et confirmer aucune r√©gression

### Actions

#### 5.1. D√©ployer sur staging

```bash
# Merge PR apr√®s review
git checkout main
git pull origin main
git merge perf/fix-homepage-load-time

# D√©ployer staging
npm run deploy:staging
```

#### 5.2. Tests de charge

```bash
# Test avec outil diagnostic
tail -f logs/nest.log | node backend/diagnose-performance.js

# Ou tests manuels r√©p√©t√©s
for i in {1..10}; do
  curl -w "%{time_total}\n" -o /dev/null -s https://staging.app.com/
done
```

#### 5.3. Comparer m√©triques avant/apr√®s

| M√©trique | Avant | Apr√®s | Gain |
|----------|-------|-------|------|
| Homepage load | 15-20s | 3-5s | **-70%** |
| √âquipementiers √ó6 | 1.2s | 0.2s | **-83%** |
| SEO cached | 5-13s | <100ms | **-98%** |
| Cache hit rate | <30% | >70% | **+133%** |

#### 5.4. Validation business

- [ ] **Fonctionnel** : Toutes les features fonctionnent
- [ ] **Performance** : Gains mesurables confirm√©s
- [ ] **Stabilit√©** : Aucune erreur logs 500
- [ ] **SEO** : Content identique (pas de r√©gression)

#### 5.5. Monitoring production

```bash
# Activer feature flag progressif
ENABLE_CACHE_REDIS=true # 10% traffic
ENABLE_CACHE_REDIS=true # 50% traffic
ENABLE_CACHE_REDIS=true # 100% traffic

# Surveiller m√©triques Grafana
# - Response time P50/P95/P99
# - Error rate
# - Cache hit rate
# - DB query count
```

### Rollback si probl√®me

```bash
# D√©sactiver feature flag
ENABLE_CACHE_REDIS=false

# Ou rollback deploy
git revert HEAD
npm run deploy:production
```

### Outputs
- ‚úÖ Gains valid√©s production (m√©triques avant/apr√®s)
- ‚úÖ Aucune r√©gression d√©tect√©e
- ‚úÖ Monitoring alertes configur√©es

**Dur√©e estim√©e** : 1-2 heures

---

## Phase 6: Documentation üìö

### Objectif
Capitaliser learnings pour incidents futurs

### Actions

#### 6.1. Cr√©er post-mortem

**Template** : `.spec/reports/incidents/incident-YYYY-MM-DD-homepage-slow.md`

```markdown
# Incident: Homepage Slow (17 Nov 2025)

## Timeline
- 09:00: D√©tection (support client)
- 09:30: Diagnostic (logs analys√©s)
- 11:00: Cause racine (6 appels dupliqu√©s)
- 14:00: Correctifs impl√©ment√©s
- 16:00: Validation production

## Root Cause
Frontend useEffect sans d√©pendances ‚Üí infinite loop

## Solutions Applied
1. Cache Redis TTL 1h (-83%)
2. Parall√©lisation queries (-70%)
3. Fix useEffect deps

## Learnings
- ‚úÖ Diagnostic script tr√®s utile
- ‚úÖ Quick wins > optimisations complexes
- ‚ùå Monitoring insuffisant (d√©tection tardive)

## Action Items
- [ ] Ajouter alertes P95 > 3s
- [ ] ESLint rule exhaustive-deps enforced
```

#### 6.2. Mettre √† jour documentation

- **ADR** : Cr√©er ADR si d√©cision architecture (ex: ADR-003 Cache Redis)
- **README** : Ajouter section troubleshooting
- **Runbook** : Enrichir proc√©dures op√©rationnelles

#### 6.3. Partager avec l'√©quipe

- [ ] Pr√©sentation d√©mo (show & tell)
- [ ] Update wiki/confluence
- [ ] Slack announcement avec m√©triques
- [ ] Retex r√©trospective sprint

### Outputs
- ‚úÖ Post-mortem incident document√©
- ‚úÖ ADR cr√©√©s (si d√©cisions architecture)
- ‚úÖ Runbook mis √† jour
- ‚úÖ √âquipe inform√©e

**Dur√©e estim√©e** : 30-60 minutes

---

## üõ†Ô∏è Outils recommand√©s

### Diagnostic
- **Script maison** : `backend/diagnose-performance.js`
- **Logs** : `tail -f logs/nest.log`
- **DB profiler** : Supabase Dashboard > SQL Editor > EXPLAIN ANALYZE
- **Redis CLI** : `redis-cli INFO stats`
- **APM** : New Relic, Datadog (si disponible)

### Monitoring
- **Grafana** : Dashboards performance
- **Prometheus** : M√©triques custom
- **Sentry** : Error tracking
- **Logs structur√©s** : Winston avec format JSON

### Tests
- **cURL** : Tests manuels avec timings
- **k6** : Tests de charge
- **Playwright** : Tests E2E avec performance metrics
- **Jest** : Tests unitaires services

---

## üìã Checklist compl√®te

### Avant de commencer
- [ ] Incident confirm√© (logs + m√©triques)
- [ ] Priorit√© assign√©e (P0-P3)
- [ ] Owner responsable d√©fini
- [ ] Branche Git cr√©√©e

### Pendant diagnostic
- [ ] Logs analys√©s (patterns identifi√©s)
- [ ] Queries DB profil√©es (EXPLAIN ANALYZE)
- [ ] Cache stats v√©rifi√©s (hit rate)
- [ ] Cause racine document√©e

### Pendant impl√©mentation
- [ ] Quick wins prioris√©s (impact matrix)
- [ ] Code impl√©ment√© + test√©
- [ ] PR cr√©√©e + reviewed
- [ ] Tests automatis√©s ajout√©s

### Pendant validation
- [ ] D√©ploy√© staging
- [ ] M√©triques avant/apr√®s compar√©es
- [ ] Aucune r√©gression fonctionnelle
- [ ] Feature flag production progressive

### Apr√®s r√©solution
- [ ] Post-mortem r√©dig√©
- [ ] ADR cr√©√©s (si applicable)
- [ ] Monitoring alertes configur√©es
- [ ] √âquipe inform√©e (d√©mo/wiki)

---

## üéØ Success Criteria

Un workflow est r√©ussi si :

- ‚úÖ **D√©tection rapide** : < 30min incident ‚Üí diagnostic
- ‚úÖ **Fix rapide** : < 4h diagnostic ‚Üí production (P0/P1)
- ‚úÖ **Gains mesurables** : M√©triques avant/apr√®s document√©es
- ‚úÖ **Zero r√©gression** : Tests automatis√©s passent
- ‚úÖ **Documentation** : Post-mortem + ADR cr√©√©s
- ‚úÖ **Learnings partag√©s** : √âquipe inform√©e + runbook updat√©

---

## üìö R√©f√©rences

- [PERFORMANCE-OPTIMIZATIONS.md](../../PERFORMANCE-OPTIMIZATIONS.md)
- [ADR-003: Cache Redis Multi-Niveaux](../architecture/003-cache-redis-multi-levels.md)
- [ADR-004: SEO Switches Migration](../architecture/004-seo-switches-migration-php-ts.md)
- [Diagnostic Script](../../backend/diagnose-performance.js)
- [Incident Homepage 17 Nov 2025](../reports/incidents/incident-2025-11-17-homepage-slow.md) *(√† cr√©er)*

---

## üîÑ Change Log

### v1.0.0 (2025-11-17)

- Workflow initial formalis√© suite incident homepage
- 6 phases d√©finies (D√©tection ‚Üí Documentation)
- Templates et checklists ajout√©s
- Outils recommand√©s list√©s
